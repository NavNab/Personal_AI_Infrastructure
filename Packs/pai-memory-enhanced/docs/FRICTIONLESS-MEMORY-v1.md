# Frictionless Memory v1.0

**Built:** 2026-01-13
**Turns Used:** 18/1000
**Status:** Production Ready âœ…

---

## The Problem

Claude Code loses context between sessions. Users had to repeatedly tell Claude their preferences, decisions, and corrections. Raw session data was captured but never synthesized into actionable knowledge.

## The Solution

Automatic learning extraction from conversation transcripts using local LLMs, with zero user friction.

---

## Architecture

```
Session End â†’ Stop Hook â†’ Pipeline â†’ Persistent Memory
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  stop-hook-learning-extractor.ts                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                  â”‚
â”‚  Receives: { session_id, transcript_path }                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TranscriptReader.ts                                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                  â”‚
â”‚  â€¢ Parses JSONL transcripts                                  â”‚
â”‚  â€¢ Extracts text from content blocks                         â”‚
â”‚  â€¢ Achieves 97-98% token reduction                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SignalSampler.ts                                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                  â”‚
â”‚  â€¢ Scores messages by learning signals                       â”‚
â”‚  â€¢ Priority: preference > decision > correction              â”‚
â”‚  â€¢ Fits to 18K token budget                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LearningExtractor.ts                                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                  â”‚
â”‚  â€¢ Calls local LLM via Ollama HTTP API                       â”‚
â”‚  â€¢ Model fallback: qwen3:4b â†’ deepseek-r1:8b                 â”‚
â”‚  â€¢ Multi-strategy JSON parsing                               â”‚
â”‚  â€¢ Filters USER messages only                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â–¼                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SessionEnd.hook.ts  â”‚    â”‚  HandoffGenerator.ts            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”‚
â”‚  â†’ hypotheses.jsonl  â”‚    â”‚  â†’ handoffs/latest.md           â”‚
â”‚  (learnings saved)   â”‚    â”‚  â†’ handoffs/YYYY-MM-DD_*.md     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Files Created

| File | Location | Lines | Purpose |
|------|----------|-------|---------|
| `TranscriptReader.ts` | `lib/extractors/` | 200 | Parse JSONL transcripts |
| `SignalSampler.ts` | `lib/extractors/` | 220 | Smart message sampling |
| `LearningExtractor.ts` | `lib/extractors/` | 560 | LLM extraction pipeline |
| `HandoffGenerator.ts` | `lib/extractors/` | 270 | Handoff generation |
| `stop-hook-learning-extractor.ts` | `hooks/` | 215 | Wires pipeline |

---

## Performance

| Metric | Value |
|--------|-------|
| Token reduction | 97-98% |
| Extraction time | ~8 seconds |
| Primary model | qwen3:4b (13.6s) |
| Fallback model | deepseek-r1:8b (30.4s) |
| Timeout | 45 seconds |

---

## Signal Detection Patterns

```typescript
const LEARNING_SIGNALS = {
  preference: [
    /\bi\s+(prefer|like|want|need|always|never)\b/i,
    /\bkeep\s+it\s+simple/i,
    /\bdon['']t\s+(want|like|need)/i,
  ],
  decision: [
    /\b(let['']s|we['']ll|we\s+should|decided|going\s+to)\b/i,
  ],
  correction: [
    /\b(no|not|actually|wrong|incorrect)\b/i,
    /\bthe\s+(question|point|issue)\s+is\b/i,
  ],
};
```

---

## JSON Parsing Strategies

1. **Code blocks**: Extract from \`\`\`json...\`\`\`
2. **Balanced objects**: Find properly nested `{...}`
3. **Direct arrays**: Handle `[...]` without wrapper
4. **Greedy match**: Last resort `{.*}`

Pre-processing:
- Strip `<think>...</think>` tags (deepseek-r1)
- Remove "Thinking..." prefix (qwen3)

---

## Configuration

Settings in `~/.claude/settings.json`:

```json
{
  "hooks": {
    "Stop": [{
      "matcher": "*",
      "hooks": [{
        "type": "command",
        "command": "bun run $PAI_DIR/hooks/stop-hook-learning-extractor.ts"
      }]
    }]
  }
}
```

---

## Output Examples

### Handoff (MEMORY/handoffs/latest.md)

```markdown
# Session Handoff

**Created:** 2026-01-13
**Session:** de8e78e6...
**Topic:** Feature Development

## Learnings Captured

### Preferences

- ğŸŸ¢ User prefers simple implementations first *(evidence: "keep it simple...")*
```

### Hypothesis (MEMORY/hypotheses.jsonl)

```json
{
  "statement": "User prefers simple implementations first",
  "tags": ["preference", "session-learning"],
  "observationCount": 1,
  "status": "open"
}
```

---

## Research Journey

| Phase | Turns | Focus |
|-------|-------|-------|
| Research | 1-11 | Transcript structure, LLM testing, prompt design |
| Implementation | 12-16 | Build all components |
| Hardening | 17-18 | Model fallback, JSON parsing |

**Key discoveries:**
- Transcripts at `~/.claude/projects/{hash}/{session}.jsonl`
- Content blocks: `thinking` (skip), `text` (keep), `tool_use` (skip)
- qwen3:4b faster (13s) but sometimes ignores format
- deepseek-r1:8b slower (30s) but more reliable
- User-only filtering reduces LLM confusion

---

## Future Enhancements

1. **Claude Haiku fallback** for higher quality
2. **Pattern detection** across sessions
3. **Auto-promotion** (5 observations â†’ fact)
4. **Cross-session analysis**
5. **Local embeddings** for semantic search

---

*Frictionless Memory: Because Claude should remember what matters.*
